# 6D Object Pose Estimation

End-to-end pipeline for 6D object pose estimation using RGB-D images. The project implements object detection and pose prediction techniques, progressively incorporating depth information to improve estimation accuracy.

## ğŸ¯ Project Overview

This project focuses on 6D pose estimation, which determines both the **3D position** (translation vector) and **3D orientation** (rotation matrix) of objects in space. The pipeline combines:

- **Object Detection**: Localizing objects in RGB images using pretrained models (e.g., YOLO11)
- **Pose Estimation**: Predicting 6D pose from detected regions using CNN-based architectures
- **RGB-D Fusion**: Enhancing predictions by incorporating depth information

The implementation follows a modular structure with clear separation of concerns, enabling easy experimentation and extension.

## ğŸ“ Project Structure

```
polito-aml-6D_pose_estimation/
â”œâ”€â”€ checkpoints/                  # ğŸ’¾ MODEL CHECKPOINTS (created during training)
â”‚   â”œâ”€â”€ pretrained/               # Pretrained weights (yolo11n.pt, yolov8n.pt)
â”‚   â”œâ”€â”€ yolo/                     # YOLO fine-tuned models (organized structure)
â”‚   â”‚   â””â”€â”€ yolo_head_only/       # Training run folder (auto-organized after training)
â”‚   â”‚       â”œâ”€â”€ plots/            # Training curves (F1, PR, confusion matrix)
â”‚   â”‚       â”œâ”€â”€ training_samples/ # Sample training batches (JPG)
â”‚   â”‚       â”œâ”€â”€ validation_samples/  # Sample validation batches (JPG)
â”‚   â”‚       â”œâ”€â”€ weights/          # Model weights (best.pt, last.pt)
â”‚   â”‚       â”œâ”€â”€ args.yaml         # Training configuration
â”‚   â”‚       â””â”€â”€ results.csv       # Per-epoch metrics
â”‚   â”œâ”€â”€ best_model.pth            # Best PoseEstimator model (gitignored)
â”‚   â””â”€â”€ checkpoint_epoch_N.pth    # Periodic PoseEstimator checkpoints (gitignored)
â”‚
â”œâ”€â”€ data/                         # ğŸ“ DATASET FILES (LineMOD subset - download separately)
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ Linemod_preprocessed/     # LineMOD dataset
â”‚       â”œâ”€â”€ data/                 # RGB-D images (01-15 objects)
â”‚       â”œâ”€â”€ models/               # 3D object models (.ply)
â”‚       â””â”€â”€ yolo_symlinks/        # YOLO-format dataset (symlinks)
â”‚           â”œâ”€â”€ images/           # train/, val/ splits
â”‚           â”œâ”€â”€ labels/           # YOLO annotations
â”‚           â””â”€â”€ data.yaml         # Dataset config
â”‚
â”œâ”€â”€ dataset/                      # ğŸ“¦ DATASET MODULE
â”‚   â”œâ”€â”€ __init__.py               # Dataset exports
â”‚   â”œâ”€â”€ custom_dataset.py         # PyTorch Dataset for pose estimation
â”‚   â””â”€â”€ linemod_yolo_dataset.py   # YOLO dataset preparation
â”‚
â”œâ”€â”€ models/                       # ğŸ§  MODELS MODULE
â”‚   â”œâ”€â”€ __init__.py               # Model exports
â”‚   â”œâ”€â”€ yolo_detector.py          # YOLO11-based object detection (freeze/train/validate)
â”‚   â””â”€â”€ pose_estimator.py         # 6D pose estimation (ResNet-50 + regression head)
â”‚
â”œâ”€â”€ notebooks/                    # ğŸ““ JUPYTER NOTEBOOKS
â”‚   â”œâ”€â”€ colab_training.ipynb      # Google Colab training workflow
â”‚   â””â”€â”€ Enhancing_6DPose_Estimation.ipynb  # Educational notebook
â”‚
â”œâ”€â”€ notebooks test/               # ğŸ§ª TEST NOTEBOOKS
â”‚   â”œâ”€â”€ test_explore_dataset.ipynb       # Dataset exploration & statistics
â”‚   â”œâ”€â”€ test_yolo1_pretrained.ipynb      # YOLO pretrained detection baseline
â”‚   â”œâ”€â”€ test_yolo2_finetuning.ipynb      # YOLO fine-tuning & validation (mAP metrics)
â”‚   â””â”€â”€ test_yolo3_pose_estimation.ipynb # Pose estimation testing & 3D visualization
|
|
â”œâ”€â”€ utils/                        # ğŸ› ï¸ UTILITIES MODULE
â”‚   â”œâ”€â”€ __init__.py               # Utility exports
â”‚   â”œâ”€â”€ download_dataset.py       # Dataset downloader
â”‚   â”œâ”€â”€ transforms.py             # Pose transformations (quaternion, rotation, cropping)
â”‚   â”œâ”€â”€ losses.py                 # Loss functions (translation + rotation)
â”‚   â”œâ”€â”€ metrics.py                # Evaluation metrics (ADD, ADD-S)
â”‚   â”œâ”€â”€ bbox_utils.py             # Bounding box utilities
â”‚   â”œâ”€â”€ prepare_yolo_symlinks.py  # Create YOLO dataset with symlinks
â”‚   â””â”€â”€ organize_yolo_results.py  # Auto-organize YOLO outputs into subdirectories
â”‚
â”œâ”€â”€ config.py                     # âš™ï¸ CONFIGURATION (hyperparameters, paths, M4 optimizations)
â”œâ”€â”€ requirements.txt              # ğŸ“‹ PYTHON DEPENDENCIES (pip install -r requirements.txt)
â”œâ”€â”€ .gitignore                    # ğŸš« GIT IGNORE (data/, checkpoints/*.pth, wandb/)
â”‚
â””â”€â”€ README.md
```

## ğŸ¯ Key Components

âœ… **Modularity**: Code split into reusable modules (dataset, models, utils)

âœ… **CLI Interface**: Argparse for flexible script execution

âœ… **Reproducibility**: requirements.txt + config.py for consistent experiments

âœ… **Checkpoint Management**: Automatic model saving

âœ… **Logging**: Wandb integration for experiment tracking

âœ… **Documentation**: Clear structure and documentation

âœ… **Git-friendly**: Proper .gitignore for large files

## ğŸ” Module Overview

**Dataset Module** (`dataset/`): Handles data loading for RGB-D images, bounding boxes, and 6D pose annotations. Includes `PoseDataset` class that loads LineMOD samples from official train/test splits, crops objects using bounding boxes, and converts rotation matrices to quaternions.

**Models Module** (`models/`):

- `yolo_detector.py`: yolo-based object detection wrapper
- `pose_estimator.py`: 6D pose estimation using ResNet-50 backbone + regression head outputting quaternion (4D) + translation (3D)

**Utils Module** (`utils/`):

- `download_dataset.py`: Dataset downloader
- `transforms.py`: Pose transformations (rotation matrix â†” quaternion, bbox cropping, 3D point projection)
- `losses.py`: Combined loss function (L1 smooth for translation + geodesic distance for rotation)
- `metrics.py`: ADD and ADD-S metrics with 3D model loading

**Notebooks** (`notebooks/`): Jupyter notebooks for Colab training and educational purposes

**Test** (`test/`):

- `test_yolo.ipynb`: Detection baseline testing with ground truth comparison
- `test_pose_estimation.ipynb`: Pose prediction visualization with 3D bounding boxes, per-object ADD analysis

**Config** (`config.py`): Centralized configuration including detection parameters (YOLO), pose estimation parameters (batch size, learning rate, loss weights), and object information (symmetric objects, ID-to-name mapping)

## ğŸ”„ Typical Workflow

### 1. Initial Setup

```bash
git clone <repo-url>
cd polito-aml-6D_pose_estimation
pip install -r requirements.txt
python utils/download_dataset.py
```

> **ğŸ“ Note on Checkpoints**: All models save in `checkpoints/`:
> - YOLO models: `checkpoints/yolo/`
> - Pose models: `checkpoints/*.pth`

**Device Detection:**
The system automatically detects the best available device (CUDA > MPS > CPU).
Test your device with:

```bash
python test_device.py
```

On **Apple Silicon Mac** (M1/M2/M3), MPS (Metal Performance Shaders) will be automatically enabled for ~5-10x speedup vs CPU.

### 2. Training (6D Pose Estimation)

**Training Modes:**

| Mode | Command | Time (Mac M1/M2) | Params Trained | Quality | Use Case |
|------|---------|------------------|----------------|---------|----------|
| **Quick Test** | `--freeze_backbone --epochs 2` | 2-3 min | ~3M (head only) | Basic | Fast prototyping |
| **Medium** | `--epochs 5` | 10-15 min | ~26M (full) | Good | Quick experiments |
| **Full** | `--epochs 50` | 2-4 hours | ~26M (full) | Best | Final model |

**Key Training Features:**

- **Gradient Accumulation**: Effective batch size = batch_size Ã— gradient_accum_steps
- **Mixed Precision (FP16)**: Faster training on Apple Silicon / CUDA GPUs
- **Validation with ADD Metric**: Computed every 5 epochs using official test split
- **Automatic Checkpointing**: Best model saved based on validation ADD
- **Wandb Logging**: Track experiments with Weights & Biases

### 3. Testing & Evaluation

```bash
# Test detection baseline
jupyter notebook test/test_yolo.ipynb

# Evaluate pose estimation on test set
jupyter notebook test/test_pose_estimation.ipynb
```

**Evaluation Metrics:**

- **ADD (Average Distance of Model Points)**: Mean distance between transformed 3D points
- **ADD-S**: Symmetric variant for objects like eggbox (obj_08) and glue (obj_09)
- **Accuracy**: Percentage of predictions with ADD < 10% of object diameter

## ğŸ“¢ Release Information

**ğŸ“… Last update:** November 2025  
**ğŸ·ï¸ Version:** v1.0.0

*For details on changes and fixes, see the changelog in the repository.*
