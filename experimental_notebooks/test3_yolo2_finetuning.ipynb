{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4903668b",
   "metadata": {},
   "source": [
    "# Yolo FineTuning su dataset Linemood\n",
    "\n",
    "Questo notebook permette di:\n",
    "1. **Carica YOLO pretrained**\n",
    "2. **Fine-tuning solo della head** (classification head)\n",
    "3. **Inferenza sul Test Set e salvataggio metriche valutazione** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ceebf",
   "metadata": {},
   "source": [
    "## 1. Import e Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661d9632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache Strategy: full\n",
      "Numworkers set to 0\n",
      "Numworkers set to 0\n",
      "‚úÖ Setup completato\n",
      "üìÇ Project root: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation\n",
      "üéØ Classi LineMOD: 13\n",
      "üñ•Ô∏è  Device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Importa il config per usare path e file in altre cartelle\n",
    "sys.path.insert(0, str(Path.cwd().parent))  # Aggiungi parent al path\n",
    "from config import Config\n",
    "from models.yolo_detector import YOLODetector\n",
    "from models.yolo_detector import visualize_detections\n",
    "from utils.prepare_yolo_symlinks import prepare_yolo_dataset_symlinks, create_data_yaml\n",
    "from utils.organize_yolo_results import organize_yolo_output, print_organization_summary\n",
    "\n",
    "\n",
    "# Usa PROJECT_ROOT dal config\n",
    "project_root = Config.PROJECT_ROOT\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Configura matplotlib per notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"‚úÖ Setup completato\")\n",
    "print(f\"üìÇ Project root: {project_root}\")\n",
    "print(f\"üéØ Classi LineMOD: {Config.NUM_CLASSES}\")\n",
    "print(f\"üñ•Ô∏è  Device: {Config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03126d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loading pretrained yolo11n from cache: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/checkpoints/pretrained/yolo11n.pt\n",
      "‚ö†Ô∏è  COCO pretrained weights have 80 classes, but you have 13 classes\n",
      "üîÑ Modifying detection head...\n",
      "   ‚úÖ Modified detection head: 80 ‚Üí 13 classes\n",
      "   üìä Output channels per scale: 18 (4 bbox + 1 obj + 13 classes)\n",
      "\n",
      "üìä Modello YOLO caricato:\n",
      "   Parametri totali: 2,624,080\n",
      "\n",
      "üìã Model Summary (Layer Interni):\n",
      "================================================================================\n",
      "YOLO11n summary: 181 layers, 2,624,080 parameters, 0 gradients\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(181, 2624080, 0, 0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = YOLODetector(\n",
    "    model_name=Config.YOLO_MODEL,  # cambiare con nome di un modello gi√† allenato per continuare da questo\n",
    "    pretrained=True,\n",
    "    num_classes=Config.NUM_CLASSES  # LineMOD ha 13 classi (la testa viene modificata automaticamente)\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Modello YOLO caricato:\")\n",
    "print(f\"   Parametri totali: {detector.model_info['parameters']:,}\")\n",
    "\n",
    "# Mostra summary dettagliato del modello\n",
    "print(\"\\nüìã Model Summary (Layer Interni):\")\n",
    "print(\"=\"*80)\n",
    "detector.model.info(verbose=True, detailed=False)  # verbose=True per vedere tutti i layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41882de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset gi√† preparato: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/data/Linemod_preprocessed/yolo_symlinks\n",
      "\n",
      "üìÑ Config file: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/data/Linemod_preprocessed/yolo_symlinks/data.yaml\n"
     ]
    }
   ],
   "source": [
    "output_dir = Config.LINEMOD_ROOT / 'yolo_symlinks'\n",
    "\n",
    "# Prepara dataset se non esiste\n",
    "if (output_dir / 'data.yaml').exists():\n",
    "    print(f\"‚úÖ Dataset gi√† preparato: {output_dir}\")\n",
    "    data_yaml_path = output_dir / 'data.yaml'\n",
    "else:\n",
    "    print(\"‚ö° Preparazione dataset con symlinks...\")\n",
    "    stats = prepare_yolo_dataset_symlinks(\n",
    "        dataset_root=Config.LINEMOD_ROOT,\n",
    "        output_root=output_dir,\n",
    "        use_symlinks=True\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Dataset preparato in {stats['time_seconds']:.1f}s\")\n",
    "    print(f\"   Train: {stats['train']} immagini\")\n",
    "    print(f\"   Val: {stats['val']} immagini\")\n",
    "    \n",
    "    data_yaml_path = create_data_yaml(output_dir, Config.DATASETS_DIR)\n",
    "\n",
    "print(f\"\\nüìÑ Config file: {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d3bcc",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning solo della head\n",
    "\n",
    "YOLO11n architecture (22 total layers, 0-21):\n",
    "- Layer 0-9:   Backbone (feature extraction - CSPDarknet) \n",
    "- Layer 10-21: Neck + Head (feature fusion + detection)\n",
    "\n",
    "ATTENZIONE: Yolo ha si 22 layer ma esplorando l'architettura se ne vedono molti di pi√π (penso sia perch√® sono blocchi di layer ripetuti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367dcfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùÑÔ∏è  Congelamento del backbone in corso...\n",
      "\n",
      "üîí Freezing backbone until layer 10...\n",
      "\n",
      "üìä Parameter Statistics:\n",
      "   Total: 2,624,080\n",
      "   Frozen: 1,115,744 (42.5%)\n",
      "   Trainable: 1,508,336 (57.5%)\n",
      "\n",
      "‚úÖ Backbone frozen! Only detection head will be trained.\n",
      "\n",
      "‚úÖ Backbone congelato fino al layer 10\n",
      "   Layer 10-21 sono trainable (neck/head)\n",
      "\n",
      "üîç Stato Congelamento Layer:\n",
      "------------------------------------------------------------\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.0.conv.weight                          |        432 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.0.bn.weight                            |         16 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.0.bn.bias                              |         16 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.1.conv.weight                          |      4,608 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.1.bn.weight                            |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.1.bn.bias                              |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.cv1.conv.weight                      |      1,024 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.cv1.bn.weight                        |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.cv1.bn.bias                          |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.cv2.conv.weight                      |      3,072 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.cv2.bn.weight                        |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.cv2.bn.bias                          |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.m.0.cv1.conv.weight                  |      1,152 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.m.0.cv1.bn.weight                    |          8 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.m.0.cv1.bn.bias                      |          8 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.m.0.cv2.conv.weight                  |      1,152 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.m.0.cv2.bn.weight                    |         16 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.2.m.0.cv2.bn.bias                      |         16 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.3.conv.weight                          |     36,864 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.3.bn.weight                            |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.3.bn.bias                              |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.cv1.conv.weight                      |      4,096 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.cv1.bn.weight                        |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.cv1.bn.bias                          |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.cv2.conv.weight                      |     12,288 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.cv2.bn.weight                        |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.cv2.bn.bias                          |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.m.0.cv1.conv.weight                  |      4,608 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.m.0.cv1.bn.weight                    |         16 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.m.0.cv1.bn.bias                      |         16 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.m.0.cv2.conv.weight                  |      4,608 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.m.0.cv2.bn.weight                    |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.4.m.0.cv2.bn.bias                      |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.5.conv.weight                          |    147,456 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.5.bn.weight                            |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.5.bn.bias                              |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.cv1.conv.weight                      |     16,384 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.cv1.bn.weight                        |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.cv1.bn.bias                          |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.cv2.conv.weight                      |     24,576 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.cv2.bn.weight                        |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.cv2.bn.bias                          |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv1.conv.weight                  |      2,048 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv1.bn.weight                    |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv1.bn.bias                      |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv2.conv.weight                  |      2,048 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv2.bn.weight                    |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv2.bn.bias                      |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv3.conv.weight                  |      4,096 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv3.bn.weight                    |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.cv3.bn.bias                      |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.0.cv1.conv.weight              |      9,216 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.0.cv1.bn.weight                |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.0.cv1.bn.bias                  |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.0.cv2.conv.weight              |      9,216 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.0.cv2.bn.weight                |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.0.cv2.bn.bias                  |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.1.cv1.conv.weight              |      9,216 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.1.cv1.bn.weight                |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.1.cv1.bn.bias                  |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.1.cv2.conv.weight              |      9,216 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.1.cv2.bn.weight                |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.6.m.0.m.1.cv2.bn.bias                  |         32 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.7.conv.weight                          |    294,912 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.7.bn.weight                            |        256 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.7.bn.bias                              |        256 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.cv1.conv.weight                      |     65,536 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.cv1.bn.weight                        |        256 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.cv1.bn.bias                          |        256 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.cv2.conv.weight                      |     98,304 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.cv2.bn.weight                        |        256 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.cv2.bn.bias                          |        256 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv1.conv.weight                  |      8,192 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv1.bn.weight                    |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv1.bn.bias                      |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv2.conv.weight                  |      8,192 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv2.bn.weight                    |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv2.bn.bias                      |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv3.conv.weight                  |     16,384 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv3.bn.weight                    |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.cv3.bn.bias                      |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.0.cv1.conv.weight              |     36,864 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.0.cv1.bn.weight                |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.0.cv1.bn.bias                  |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.0.cv2.conv.weight              |     36,864 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.0.cv2.bn.weight                |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.0.cv2.bn.bias                  |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.1.cv1.conv.weight              |     36,864 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.1.cv1.bn.weight                |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.1.cv1.bn.bias                  |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.1.cv2.conv.weight              |     36,864 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.1.cv2.bn.weight                |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.8.m.0.m.1.cv2.bn.bias                  |         64 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.9.cv1.conv.weight                      |     32,768 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.9.cv1.bn.weight                        |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.9.cv1.bn.bias                          |        128 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.9.cv2.conv.weight                      |    131,072 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.9.cv2.bn.weight                        |        256 params\n",
      "Layer model | ‚ùÑÔ∏è  FROZEN | model.model.9.cv2.bn.bias                          |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.cv1.conv.weight                     |     65,536 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.cv1.bn.weight                       |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.cv1.bn.bias                         |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.cv2.conv.weight                     |     65,536 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.cv2.bn.weight                       |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.cv2.bn.bias                         |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.qkv.conv.weight            |     32,768 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.qkv.bn.weight              |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.qkv.bn.bias                |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.proj.conv.weight           |     16,384 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.proj.bn.weight             |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.proj.bn.bias               |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.pe.conv.weight             |      1,152 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.pe.bn.weight               |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.attn.pe.bn.bias                 |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.ffn.0.conv.weight               |     32,768 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.ffn.0.bn.weight                 |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.ffn.0.bn.bias                   |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.ffn.1.conv.weight               |     32,768 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.ffn.1.bn.weight                 |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.10.m.0.ffn.1.bn.bias                   |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.cv1.conv.weight                     |     49,152 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.cv1.bn.weight                       |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.cv1.bn.bias                         |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.cv2.conv.weight                     |     24,576 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.cv2.bn.weight                       |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.cv2.bn.bias                         |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.m.0.cv1.conv.weight                 |     18,432 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.m.0.cv1.bn.weight                   |         32 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.m.0.cv1.bn.bias                     |         32 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.m.0.cv2.conv.weight                 |     18,432 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.m.0.cv2.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.13.m.0.cv2.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.cv1.conv.weight                     |     16,384 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.cv1.bn.weight                       |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.cv1.bn.bias                         |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.cv2.conv.weight                     |      6,144 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.cv2.bn.weight                       |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.cv2.bn.bias                         |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.m.0.cv1.conv.weight                 |      4,608 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.m.0.cv1.bn.weight                   |         16 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.m.0.cv1.bn.bias                     |         16 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.m.0.cv2.conv.weight                 |      4,608 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.m.0.cv2.bn.weight                   |         32 params\n",
      "Layer model | üî• TRAINABLE | model.model.16.m.0.cv2.bn.bias                     |         32 params\n",
      "Layer model | üî• TRAINABLE | model.model.17.conv.weight                         |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.17.bn.weight                           |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.17.bn.bias                             |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.cv1.conv.weight                     |     24,576 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.cv1.bn.weight                       |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.cv1.bn.bias                         |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.cv2.conv.weight                     |     24,576 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.cv2.bn.weight                       |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.cv2.bn.bias                         |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.m.0.cv1.conv.weight                 |     18,432 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.m.0.cv1.bn.weight                   |         32 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.m.0.cv1.bn.bias                     |         32 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.m.0.cv2.conv.weight                 |     18,432 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.m.0.cv2.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.19.m.0.cv2.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.20.conv.weight                         |    147,456 params\n",
      "Layer model | üî• TRAINABLE | model.model.20.bn.weight                           |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.20.bn.bias                             |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.cv1.conv.weight                     |     98,304 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.cv1.bn.weight                       |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.cv1.bn.bias                         |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.cv2.conv.weight                     |     98,304 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.cv2.bn.weight                       |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.cv2.bn.bias                         |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv1.conv.weight                 |      8,192 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv1.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv1.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv2.conv.weight                 |      8,192 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv2.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv2.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv3.conv.weight                 |     16,384 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv3.bn.weight                   |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.cv3.bn.bias                     |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.0.cv1.conv.weight             |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.0.cv1.bn.weight               |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.0.cv1.bn.bias                 |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.0.cv2.conv.weight             |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.0.cv2.bn.weight               |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.0.cv2.bn.bias                 |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.1.cv1.conv.weight             |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.1.cv1.bn.weight               |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.1.cv1.bn.bias                 |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.1.cv2.conv.weight             |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.1.cv2.bn.weight               |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.22.m.0.m.1.cv2.bn.bias                 |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.0.0.conv.weight                 |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.0.0.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.0.0.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.0.1.conv.weight                 |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.0.1.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.0.1.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.0.2.weight                      |      4,096 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.0.2.bias                        |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.1.0.conv.weight                 |     73,728 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.1.0.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.1.0.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.1.1.conv.weight                 |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.1.1.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.1.1.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.1.2.weight                      |      4,096 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.1.2.bias                        |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.2.0.conv.weight                 |    147,456 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.2.0.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.2.0.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.2.1.conv.weight                 |     36,864 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.2.1.bn.weight                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.2.1.bn.bias                     |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.2.2.weight                      |      4,096 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv2.2.2.bias                        |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.0.0.conv.weight               |        576 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.0.0.bn.weight                 |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.0.0.bn.bias                   |         64 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.0.1.conv.weight               |      5,120 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.0.1.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.0.1.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.1.0.conv.weight               |        720 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.1.0.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.1.0.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.1.1.conv.weight               |      6,400 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.1.1.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.1.1.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.2.weight                      |      6,400 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.0.2.bias                        |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.0.0.conv.weight               |      1,152 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.0.0.bn.weight                 |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.0.0.bn.bias                   |        128 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.0.1.conv.weight               |     10,240 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.0.1.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.0.1.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.1.0.conv.weight               |        720 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.1.0.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.1.0.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.1.1.conv.weight               |      6,400 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.1.1.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.1.1.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.2.weight                      |      6,400 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.1.2.bias                        |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.0.0.conv.weight               |      2,304 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.0.0.bn.weight                 |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.0.0.bn.bias                   |        256 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.0.1.conv.weight               |     20,480 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.0.1.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.0.1.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.1.0.conv.weight               |        720 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.1.0.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.1.0.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.1.1.conv.weight               |      6,400 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.1.1.bn.weight                 |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.1.1.bn.bias                   |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.2.weight                      |      6,400 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.cv3.2.2.bias                        |         80 params\n",
      "Layer model | üî• TRAINABLE | model.model.23.dfl.conv.weight                     |         16 params\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Freeze del backbone (mantieni solo head trainable)\n",
    "print(\"‚ùÑÔ∏è  Congelamento del backbone in corso...\\n\")\n",
    "\n",
    "# Congela i primi 10 layer (backbone) per nuova classificazione\n",
    "freeze_until = Config.YOLO_FREEZE_UNTIL_LAYER  \n",
    "stats = detector.freeze_backbone(freeze_until_layer=freeze_until)\n",
    "\n",
    "print(f\"\\n‚úÖ Backbone congelato fino al layer {freeze_until}\")\n",
    "print(f\"   Layer {freeze_until}-21 sono trainable (neck/head)\")\n",
    "\n",
    "# Visualizzazione compatta dei layer congelati\n",
    "print(\"\\nüîç Stato Congelamento Layer:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, param in detector.model.named_parameters():\n",
    "    status = \"‚ùÑÔ∏è  FROZEN\" if not param.requires_grad else \"üî• TRAINABLE\"\n",
    "    # Estrai il numero del layer (es. model.10.conv.weight -> 10)\n",
    "    layer_num = name.split('.')[1] if len(name.split('.')) > 1 else '?'\n",
    "    print(f\"Layer {layer_num:>2s} | {status} | {name[:50]:50s} | {param.numel():>10,} params\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0eb82f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Parametri di Training:\n",
      "   Epochs: 50\n",
      "   Batch size: 32\n",
      "   Image size: 416\n",
      "   LR initial: 0.01\n",
      "   LR final: 0.0001\n",
      "   Optimizer: SGD\n",
      "   Warmup epochs: 3\n",
      "   Cosine annealing: True\n",
      "   AMP: False\n",
      "   Num WORKERS: 0\n",
      "\n",
      "\n",
      "üöÇ Starting YOLO training...\n",
      "   Model: yolo11n\n",
      "   Epochs: 50\n",
      "   Image size: 416\n",
      "   Batch size: 32\n",
      "   LR (initial ‚Üí final): 0.01 ‚Üí 0.0001\n",
      "   Optimizer: SGD\n",
      "   Device: mps\n",
      "New https://pypi.org/project/ultralytics/8.3.238 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.234 üöÄ Python-3.13.3 torch-2.9.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/data/Linemod_preprocessed/yolo_symlinks/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/checkpoints/pretrained/yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_train502, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/checkpoints/yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/checkpoints/yolo/yolo_train502, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=13\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    433207  ultralytics.nn.modules.head.Detect           [13, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,592,375 parameters, 2,592,359 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1140.6¬±417.9 MB/s, size: 447.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/data/Linemod_preprocessed/yolo_symlinks/labels/train... 2373 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2373/2373 4.4Kit/s 0.5s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/data/Linemod_preprocessed/yolo_symlinks/labels/train.cache\n",
      "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.9GB RAM): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2373/2373 1.6Kit/s 1.5s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1204.8¬±539.6 MB/s, size: 474.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/data/Linemod_preprocessed/yolo_symlinks/labels/val... 13407 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13407/13407 4.4Kit/s 3.1s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/data/Linemod_preprocessed/yolo_symlinks/labels/val.cache\n",
      "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (4.9GB RAM): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13407/13407 1.6Kit/s 8.6s<0.0s\n",
      "Plotting labels to /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/checkpoints/yolo/yolo_train502/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/checkpoints/yolo/yolo_train502\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      4.46G      1.457      4.285      1.293          8        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8it/s 41.5s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.2it/s 2:56<0.6s\n",
      "                   all      13407      21218     0.0123       0.42     0.0703     0.0493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      4.41G      1.344      2.394      1.201         20        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.5it/s 50.7s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 4% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/210 3.3s/it 35.5s<11:0331WARNING ‚ö†Ô∏è NMS time limit 5.200s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 53% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 111/210 1.3it/s 2:23<1:15WARNING ‚ö†Ô∏è NMS time limit 5.200s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 53% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 112/210 1.0s/it 2:32<1:42WARNING ‚ö†Ô∏è NMS time limit 5.200s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 54% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 113/210 1.4s/it 2:40<2:17WARNING ‚ö†Ô∏è NMS time limit 5.200s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 54% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 114/210 1.9s/it 2:48<3:00WARNING ‚ö†Ô∏è NMS time limit 5.200s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 55% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 115/210 3.5s/it 3:00<5:30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Num WORKERS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mConfig.NUM_WORKERS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Avvia training (ora i parametri ottimizzati sono defaults nel metodo train())\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m results = \u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_yaml\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_yaml_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproject_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRUN_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAMP_YOLO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ‚úÖ Auto: True su CUDA (Windows), False su MPS (Mac)\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Training completato!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Modello salvato in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/models/yolo_detector.py:274\u001b[39m, in \u001b[36mYOLODetector.train\u001b[39m\u001b[34m(self, data_yaml, epochs, imgsz, batch_size, lr0, lrf, project, name, **kwargs)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;66;03m# Merge with user-provided kwargs (user kwargs override defaults)\u001b[39;00m\n\u001b[32m    272\u001b[39m default_params.update(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Training completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/ultralytics/engine/model.py:773\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/ultralytics/engine/trainer.py:243\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    240\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/ultralytics/engine/trainer.py:478\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.val \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stopper.possible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._clear_memory(threshold=\u001b[32m0.5\u001b[39m)  \u001b[38;5;66;03m# prevent VRAM spike\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     \u001b[38;5;28mself\u001b[39m.metrics, \u001b[38;5;28mself\u001b[39m.fitness = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# NaN recovery\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_nan_recovery(epoch):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/ultralytics/engine/trainer.py:704\u001b[39m, in \u001b[36mBaseTrainer.validate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    702\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ema.ema.buffers():\n\u001b[32m    703\u001b[39m         dist.broadcast(buffer, src=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m704\u001b[39m metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/ultralytics/engine/validator.py:223\u001b[39m, in \u001b[36mBaseValidator.__call__\u001b[39m\u001b[34m(self, trainer, model)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dt[\u001b[32m3\u001b[39m]:\n\u001b[32m    221\u001b[39m     preds = \u001b[38;5;28mself\u001b[39m.postprocess(preds)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.plots \u001b[38;5;129;01mand\u001b[39;00m batch_i < \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mself\u001b[39m.plot_val_samples(batch, batch_i)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/ultralytics/models/yolo/detect/val.py:184\u001b[39m, in \u001b[36mDetectionValidator.update_metrics\u001b[39m\u001b[34m(self, preds, batch)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mcls\u001b[39m = pbatch[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].cpu().numpy()\n\u001b[32m    181\u001b[39m no_pred = predn[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m0\u001b[39m] == \u001b[32m0\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics.update_stats(\n\u001b[32m    183\u001b[39m     {\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         **\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbatch\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    185\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtarget_cls\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m    186\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtarget_img\u001b[39m\u001b[33m\"\u001b[39m: np.unique(\u001b[38;5;28mcls\u001b[39m),\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mconf\u001b[39m\u001b[33m\"\u001b[39m: np.zeros(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m no_pred \u001b[38;5;28;01melse\u001b[39;00m predn[\u001b[33m\"\u001b[39m\u001b[33mconf\u001b[39m\u001b[33m\"\u001b[39m].cpu().numpy(),\n\u001b[32m    188\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpred_cls\u001b[39m\u001b[33m\"\u001b[39m: np.zeros(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m no_pred \u001b[38;5;28;01melse\u001b[39;00m predn[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].cpu().numpy(),\n\u001b[32m    189\u001b[39m     }\n\u001b[32m    190\u001b[39m )\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.plots:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/ultralytics/models/yolo/detect/val.py:287\u001b[39m, in \u001b[36mDetectionValidator._process_batch\u001b[39m\u001b[34m(self, preds, batch)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m0\u001b[39m] == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m preds[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m0\u001b[39m] == \u001b[32m0\u001b[39m:\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mtp\u001b[39m\u001b[33m\"\u001b[39m: np.zeros((preds[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.niou), dtype=\u001b[38;5;28mbool\u001b[39m)}\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m iou = \u001b[43mbox_iou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbboxes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbboxes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mtp\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.match_predictions(preds[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m], batch[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m], iou).cpu().numpy()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/ultralytics/utils/metrics.py:74\u001b[39m, in \u001b[36mbox_iou\u001b[39m\u001b[34m(box1, box2, eps)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# NOTE: Need .float() to get accurate iou values\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)\u001b[39;00m\n\u001b[32m     73\u001b[39m (a1, a2), (b1, b2) = box1.float().unsqueeze(\u001b[32m1\u001b[39m).chunk(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m), box2.float().unsqueeze(\u001b[32m0\u001b[39m).chunk(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m inter = \u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclamp_\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# IoU = inter / (area1 + area2 - inter)\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inter / ((a2 - a1).prod(\u001b[32m2\u001b[39m) + (b2 - b1).prod(\u001b[32m2\u001b[39m) - inter + eps)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training configuration (ora usa i parametri ottimizzati da Config)\n",
    "EPOCHS = Config.YOLO_EPOCHS\n",
    "BATCH_SIZE = Config.YOLO_BATCH_SIZE\n",
    "IMG_SIZE = Config.YOLO_IMG_SIZE\n",
    "\n",
    "# Run name\n",
    "RUN_NAME = 'yolo_train50'\n",
    "project_dir = Config.CHECKPOINT_DIR / 'yolo'\n",
    "output_dir = project_dir / RUN_NAME\n",
    "\n",
    "print(f\"üîß Parametri di Training:\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Image size: {IMG_SIZE}\")\n",
    "print(f\"   LR initial: {Config.YOLO_LR_INITIAL}\")\n",
    "print(f\"   LR final: {Config.YOLO_LR_FINAL}\")\n",
    "print(f\"   Optimizer: {Config.YOLO_OPTIMIZER}\")\n",
    "print(f\"   Warmup epochs: {Config.YOLO_WARMUP_EPOCHS}\")\n",
    "print(f\"   Cosine annealing: {Config.YOLO_COS_LR}\")\n",
    "print(f\"   AMP: {Config.AMP_YOLO}\")\n",
    "print(f\"   Num WORKERS: {Config.NUM_WORKERS}\\n\")\n",
    "\n",
    "# Avvia training (ora i parametri ottimizzati sono defaults nel metodo train())\n",
    "results = detector.train(\n",
    "    data_yaml=str(data_yaml_path),\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    project=str(project_dir),\n",
    "    name=RUN_NAME,\n",
    "    save=True,\n",
    "    cache=True,\n",
    "    amp=Config.AMP_YOLO,  # ‚úÖ Auto: True su CUDA (Windows), False su MPS (Mac)\n",
    "    workers=Config.NUM_WORKERS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n\\n‚úÖ Training completato!\")\n",
    "print(f\"   Modello salvato in: {output_dir}\")\n",
    "\n",
    "# Organizza automaticamente i risultati in sottocartelle\n",
    "print(f\"\\nüìÅ Organizzazione risultati...\")\n",
    "try:\n",
    "    stats = organize_yolo_output(output_dir)\n",
    "    print_organization_summary(output_dir, stats)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Errore nell'organizzazione: {e}\")\n",
    "    print(f\"   I file sono comunque salvati in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a334a76",
   "metadata": {},
   "source": [
    "## 3. Load del modello Finetunato (inferenza e statistiche)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dafb6e",
   "metadata": {},
   "source": [
    "### Test su campione singolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il modello fine-tuned\n",
    "YOLO_NAME = 'yolo_train10'\n",
    "model_chechpoint_path = Config.CHECKPOINT_DIR / 'yolo' / YOLO_NAME\n",
    "weights_path = model_chechpoint_path / 'weights' / 'best.pt'\n",
    "\n",
    "if weights_path.exists():\n",
    "    print(f\"‚úÖ Carico modello fine-tuned: {weights_path}\\n\")\n",
    "    \n",
    "    # Import necessari    \n",
    "    finetuned_detector = YOLODetector(\n",
    "        model_name=str(weights_path),\n",
    "        num_classes=Config.NUM_CLASSES\n",
    "    )\n",
    "    \n",
    "    # Carica immagine di test se non gi√† caricata\n",
    "    if 'image' not in locals():\n",
    "        img_path = Config.LINEMOD_ROOT / 'data' / '01' / 'rgb' / '0000.png'\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        print(f\"üì∑ Immagine caricata: {img_path}\\n\")\n",
    "    else:\n",
    "        # Se gi√† caricata, mostra comunque il path\n",
    "        img_path = Config.LINEMOD_ROOT / 'data' / '01' / 'rgb' / '0000.png'\n",
    "        print(f\"üì∑ Immagine gi√† caricata: {img_path}\\n\")\n",
    "    \n",
    "    # Test sulla stessa immagine (usa Config.YOLO_CONF_THRESHOLD)\n",
    "    detections_ft = finetuned_detector.detect_objects(image)\n",
    "    \n",
    "    # Mostra i nomi delle classi predette\n",
    "    class_names_predetti = [det['class_name'] for det in detections_ft]\n",
    "    print(f\"üîé Nomi classi predetti nella detection: {class_names_predetti}\\n\")\n",
    "    \n",
    "    print(\"\\nüìä Visualizzazione detection...\\n\")\n",
    "    \n",
    "    # Visualizzazione\n",
    "    vis_ft = visualize_detections(image.copy(), detections_ft)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(vis_ft)\n",
    "    plt.title(f\"Fine-tuned LineMOD (Head only)\\n{len(detections_ft)} detection\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"‚ùå Modello non trovato: {weights_path}\")\n",
    "    print(\"   Esegui prima il training (cella precedente)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44d966",
   "metadata": {},
   "source": [
    "### Statistiche YOLO Fine Tunato\n",
    "\n",
    "**Inferenza sul Test Set e salvataggio metriche valutazione** \n",
    "\n",
    "---\n",
    "NOTA:\n",
    "\n",
    "#### Validation sul Test Set LineMOD\n",
    "\n",
    "Valutiamo le performance del modello fine-tuned sul test set ufficiale di LineMOD (mappato come \"val\" in YOLO).\n",
    "\n",
    "**Note**: \n",
    "- Il \"val\" set √® in realt√† il **test set ufficiale** di LineMOD (~85% delle immagini)\n",
    "- Il \"train\" set √® molto piccolo (~15% delle immagini) seguendo la split ufficiale\n",
    "- Metriche calcolate: mAP@0.5, mAP@0.5:0.95, Precision, Recall per classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation del modello fine-tuned sul test set\n",
    "YOLO_NAME = 'yolo_train10'\n",
    "model_chechpoint_path = Config.CHECKPOINT_DIR / 'yolo' / YOLO_NAME\n",
    "weights_path = model_chechpoint_path / 'weights' / 'best.pt'\n",
    "\n",
    "if weights_path.exists() and 'data_yaml_path' in locals():\n",
    "    print(f\"üìä Validation del modello fine-tuned su test set LineMOD\\n\")\n",
    "    print(f\"   Modello: {weights_path.name}\")\n",
    "    print(f\"   Dataset: {data_yaml_path}\\n\")\n",
    "    print(f\"‚è≥ Esecuzione validation (pu√≤ richiedere alcuni minuti)...\\n\")\n",
    "    \n",
    "    # Carica modello se non gi√† caricato\n",
    "    if 'finetuned_detector' not in locals():\n",
    "        finetuned_detector = YOLODetector(\n",
    "            model_name=str(weights_path),\n",
    "            num_classes=Config.NUM_CLASSES\n",
    "        )\n",
    "    \n",
    "    # üöÄ OTTIMIZZAZIONE: conf=0.5 riduce drasticamente le detection candidate\n",
    "    # Questo velocizza NMS di 5-10x (da ~18 min ‚Üí ~2-3 min)\n",
    "    print(f\"‚öôÔ∏è  Confidence threshold: 0.5 (riduce overhead NMS)\\n\")\n",
    "    \n",
    "    # Esegui validation (ora usa i defaults da Config)\n",
    "    metrics = finetuned_detector.validate(\n",
    "        data_yaml=str(data_yaml_path),\n",
    "        conf=Config.YOLO_CONF_THRESHOLD,  # ‚ö†Ô∏è CRITICO: riduce detection candidate per velocizzare NMS\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìà RISULTATI VALIDATION - YOLO11n Fine-tuned LineMOD\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Metriche globali\n",
    "    print(f\"üéØ Metriche Globali:\")\n",
    "    print(f\"   mAP@0.5:0.95:  {metrics.box.map:.4f}  (mean Average Precision)\")\n",
    "    print(f\"   mAP@0.5:       {metrics.box.map50:.4f}  (AP @ IoU threshold 0.5)\")\n",
    "    print(f\"   mAP@0.75:      {metrics.box.map75:.4f}  (AP @ IoU threshold 0.75)\")\n",
    "    print(f\"   Precision:     {metrics.box.mp:.4f}\")\n",
    "    print(f\"   Recall:        {metrics.box.mr:.4f}\")\n",
    "    \n",
    "    # Metriche per classe\n",
    "    print(f\"\\nüìã Metriche per Classe:\")\n",
    "    print(f\"   {'Classe':<15} {'mAP@0.5':<10} {'mAP@0.5:0.95':<15} {'Precision':<12} {'Recall':<10}\")\n",
    "    print(f\"   {'-'*70}\")\n",
    "    \n",
    "    class_names = Config.CLASS_NAMES  # Lista dei nomi delle classi\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        map50 = metrics.box.ap50[i] if i < len(metrics.box.ap50) else 0\n",
    "        map_avg = metrics.box.ap[i] if i < len(metrics.box.ap) else 0\n",
    "        prec = metrics.box.p[i] if i < len(metrics.box.p) else 0\n",
    "        rec = metrics.box.r[i] if i < len(metrics.box.r) else 0\n",
    "        \n",
    "        print(f\"   {class_name:<15} {map50:<10.4f} {map_avg:<15.4f} {prec:<12.4f} {rec:<10.4f}\")\n",
    "    \n",
    "    # Statistiche aggiuntive\n",
    "    print(f\"\\nüìä Statistiche Dataset:\")\n",
    "    print(f\"   Immagini validate: ~{len(metrics.box.ap50) * 80} immagini\")  # Stima\n",
    "    print(f\"   Classi: {Config.NUM_CLASSES}\")\n",
    "    print(f\"   Image size: {Config.YOLO_IMG_SIZE}x{Config.YOLO_IMG_SIZE}\")\n",
    "    \n",
    "    # Interpretazione risultati\n",
    "    print(f\"\\nüí° Interpretazione:\")\n",
    "    if metrics.box.map50 > 0.8:\n",
    "        print(f\"   ‚úÖ Ottimo! mAP@0.5 > 0.8 indica detection molto accurate\")\n",
    "    elif metrics.box.map50 > 0.6:\n",
    "        print(f\"   ‚úì  Buono! mAP@0.5 > 0.6 indica detection discrete\")\n",
    "    elif metrics.box.map50 > 0.4:\n",
    "        print(f\"   ‚ö†Ô∏è  Discreto. mAP@0.5 > 0.4 ma potrebbe migliorare con pi√π training\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Basso. Considerare pi√π epoche o unfreezing di pi√π layer\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Validation completata!\")\n",
    "    print(f\"   Risultati salvati in: {model_chechpoint_path}\")\n",
    "    \n",
    "else:\n",
    "    if not weights_path.exists():\n",
    "        print(f\"‚ùå Modello non trovato: {weights_path}\")\n",
    "        print(f\"   Esegui prima il training (cella 7)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Dataset YAML non trovato\")\n",
    "        print(f\"   Esegui prima la preparazione dataset (cella 4)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polito-aml-6d-pose-estimation-LevBIKLF-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
