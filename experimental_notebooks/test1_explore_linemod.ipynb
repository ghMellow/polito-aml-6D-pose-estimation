{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce295d4",
   "metadata": {},
   "source": [
    "# LineMood Dataset esplorazione\n",
    "Questo notebook serve ad esplorare il dataset linemod, per farlo ci si avvale di un custom data dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f388ec0",
   "metadata": {},
   "source": [
    "## 1. Import delle librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae68c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project root: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Importa il config per usare path e file in altre cartelle\n",
    "sys.path.insert(0, str(Path.cwd().parent))  # Aggiungi parent al path\n",
    "from config import Config\n",
    "from utils.download_dataset import download_linemod_dataset\n",
    "from dataset.custom_dataset import CustomDataset, create_dataloaders\n",
    "\n",
    "# Usa PROJECT_ROOT dal config\n",
    "project_root = Config.PROJECT_ROOT\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"üìÇ Project root: {project_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test device detection\n",
    "print(\"=\" * 60)\n",
    "print(\"üîç DEVICE DETECTION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check CUDA\n",
    "print(f\"\\nüìä CUDA (NVIDIA GPU):\")\n",
    "print(f\"   Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   Device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"   Device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Check MPS (Apple Silicon)\n",
    "print(f\"\\nüìä MPS (Apple Silicon GPU):\")\n",
    "has_mps = hasattr(torch.backends, 'mps')\n",
    "print(f\"   MPS backend available: {has_mps}\")\n",
    "if has_mps:\n",
    "    print(f\"   MPS is_available: {torch.backends.mps.is_available()}\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        try:\n",
    "            # Test MPS\n",
    "            test_tensor = torch.zeros(1).to('mps')\n",
    "            print(f\"   MPS test: ‚úÖ Working!\")\n",
    "        except Exception as e:\n",
    "            print(f\"   MPS test: ‚ùå Error - {e}\")\n",
    "\n",
    "# Show selected device\n",
    "print(f\"\\nüéØ SELECTED DEVICE:\")\n",
    "print(f\"   Config.DEVICE = '{Config.DEVICE}'\")\n",
    "\n",
    "if Config.DEVICE == 'mps':\n",
    "    print(f\"   ‚úÖ Apple Silicon GPU will be used for training\")\n",
    "    print(f\"   ‚ö° This provides ~5-10x speedup vs CPU\")\n",
    "elif Config.DEVICE == 'cuda':\n",
    "    print(f\"   ‚úÖ NVIDIA GPU will be used for training\")\n",
    "    print(f\"   ‚ö° This provides major speedup vs CPU\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  CPU will be used (slower)\")\n",
    "    print(f\"   üí° Consider using a GPU for faster training\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091042e",
   "metadata": {},
   "source": [
    "## 2. Scarica il Dataset\n",
    "\n",
    "Usa questa cella per scaricare il dataset LineMOD preprocessato.\n",
    "\n",
    "**Nota:** Il download pu√≤ richiedere alcuni minuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci la directory di output\n",
    "output_dir = Config.DATASETS_DIR\n",
    "\n",
    "# Verifica se il dataset √® gi√† presente\n",
    "dataset_path = Config.LINEMOD_ROOT\n",
    "if os.path.exists(dataset_path) and os.path.isdir(dataset_path):\n",
    "    # Verifica che non sia una cartella vuota\n",
    "    if len(os.listdir(dataset_path)) > 0:\n",
    "        print(f\"Dataset gi√† presente in {dataset_path}. Download saltato.\")\n",
    "    else:\n",
    "        print(f\"Cartella {dataset_path} vuota. Avvio download...\")\n",
    "        download_linemod_dataset(output_dir=output_dir)\n",
    "else:\n",
    "    print(f\"Dataset non trovato. Avvio download in {output_dir}...\")\n",
    "    download_linemod_dataset(output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00136f",
   "metadata": {},
   "source": [
    "## 3. Esplora la struttura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica la struttura del dataset\n",
    "data_dir = Config.DATASETS_DIR\n",
    "\n",
    "if data_dir.exists():\n",
    "    print(\"üìÅ Dataset structure:\")\n",
    "    for item in sorted(data_dir.rglob('*')):\n",
    "        if item.is_dir():\n",
    "            level = len(item.relative_to(data_dir).parts)\n",
    "            if level <= 3:  # Mostra solo i primi 3 livelli\n",
    "                indent = '  ' * level\n",
    "                print(f\"{indent}üìÅ {item.name}/\")\n",
    "        elif item.is_file() and len(item.relative_to(data_dir).parts) <= 3:\n",
    "            level = len(item.relative_to(data_dir).parts)\n",
    "            indent = '  ' * level\n",
    "            print(f\"{indent}üìÑ {item.name}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset directory not found! Please run the download cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afe0a0",
   "metadata": {},
   "source": [
    "## 4. Carica il Dataset con CustomDataset\n",
    "\n",
    "Questo codice crea oggetti Dataset (CustomDataset):\n",
    "\n",
    "- Restituisce oggetti che rappresentano la collezione di dati\n",
    "\n",
    "- Puoi accedere ai singoli sample con train_dataset[0]\n",
    "\n",
    "- NON fornisce batching automatico, shuffling, o parallelizzazione\n",
    "\n",
    "- Utile per ispezione, debugging, o quando hai bisogno di controllo manuale\n",
    "\n",
    "\n",
    "Usa quando:\n",
    "\n",
    "- Vuoi esplorare i dati singolarmente\n",
    "\n",
    "- Hai bisogno di flessibilit√† nel processing\n",
    "\n",
    "- Debugging o visualizzazione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorso al dataset\n",
    "dataset_root = Config.LINEMOD_ROOT\n",
    "\n",
    "# Crea i dataset train e test\n",
    "train_dataset = CustomDataset(dataset_root, split='train', train_ratio=Config.TRAIN_TEST_RATIO, seed=42)\n",
    "test_dataset = CustomDataset(dataset_root, split='test', train_ratio=Config.TRAIN_TEST_RATIO, seed=42)\n",
    "\n",
    "print(f\"\\nüìä Dataset info:\")\n",
    "print(f\"   Training samples: {len(train_dataset)}\")\n",
    "print(f\"   Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa9ed92",
   "metadata": {},
   "source": [
    "## üîß Test Fix: Verifica caricamento multipli oggetti per sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ce737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test per verificare che il dataset carichi correttamente tutti gli oggetti\n",
    "print(\"=\" * 80)\n",
    "print(\"üß™ Test del Dataset - Verifica caricamento multipli oggetti\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test su oggetto 02 che ha multipli oggetti per immagine\n",
    "print(\"\\nüì¶ Test su folder 02 (dovrebbe avere MULTIPLI oggetti per immagine):\")\n",
    "\n",
    "# Trova i primi 3 sample del folder 02\n",
    "folder_02_samples = [(i, s) for i, s in enumerate(train_dataset.samples) if s[0] == 2]\n",
    "\n",
    "if folder_02_samples:\n",
    "    # Testa i primi 3 samples\n",
    "    for test_idx in range(min(3, len(folder_02_samples))):\n",
    "        idx, (folder_id, sample_id) = folder_02_samples[test_idx]\n",
    "        print(f\"\\n   Sample #{test_idx+1}: idx={idx}, folder_id={folder_id}, sample_id={sample_id}\")\n",
    "        \n",
    "        sample = train_dataset[idx]\n",
    "        print(f\"   ‚úÖ Numero di oggetti trovati: {sample['num_objects']}\")\n",
    "        \n",
    "        if sample['num_objects'] > 1:\n",
    "            print(f\"   üéâ CORRETTO! Trovati {sample['num_objects']} oggetti!\")\n",
    "            for i, obj in enumerate(sample['objects'][:3]):  # Mostra max 3\n",
    "                bbox = obj['bbox'].numpy()\n",
    "                print(f\"      Oggetto {i+1}: obj_id={obj['obj_id']}, bbox=[{bbox[0]:.0f}, {bbox[1]:.0f}, {bbox[2]:.0f}, {bbox[3]:.0f}]\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è WARNING: Solo {sample['num_objects']} oggetto trovato\")\n",
    "else:\n",
    "    print(\"   ‚ùå Nessun sample trovato per folder 02\")\n",
    "\n",
    "# Test su oggetto 01 che ha un solo oggetto per immagine\n",
    "print(\"\\n\\nüì¶ Test su folder 01 (dovrebbe avere 1 SOLO oggetto per immagine):\")\n",
    "folder_01_samples = [(i, s) for i, s in enumerate(train_dataset.samples) if s[0] == 1]\n",
    "\n",
    "if folder_01_samples:\n",
    "    idx, (folder_id, sample_id) = folder_01_samples[0]\n",
    "    print(f\"   Sample: idx={idx}, folder_id={folder_id}, sample_id={sample_id}\")\n",
    "    \n",
    "    sample = train_dataset[idx]\n",
    "    print(f\"   ‚úÖ Numero di oggetti trovati: {sample['num_objects']}\")\n",
    "    \n",
    "    if sample['num_objects'] == 1:\n",
    "        print(\"   üéâ CORRETTO! Trovato 1 oggetto come previsto\")\n",
    "        obj = sample['objects'][0]\n",
    "        bbox = obj['bbox'].numpy()\n",
    "        print(f\"      Oggetto: obj_id={obj['obj_id']}, bbox=[{bbox[0]:.0f}, {bbox[1]:.0f}, {bbox[2]:.0f}, {bbox[3]:.0f}]\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è WARNING: {sample['num_objects']} oggetti trovati, dovrebbe essere 1\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4db8b2",
   "metadata": {},
   "source": [
    "## 5. Visualizza campioni del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46447c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(sample):\n",
    "    \"\"\"\n",
    "    Visualizza un campione del dataset con TUTTI i bounding box.\n",
    "    \n",
    "    Args:\n",
    "        sample: Un dizionario contenente i dati del campione\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # RGB Image\n",
    "    rgb = sample['rgb'].permute(1, 2, 0).numpy()\n",
    "    axes[0].imshow(rgb)\n",
    "    axes[0].set_title(f\"RGB Image (Objects: {sample['num_objects']})\\nFolder: {sample['folder_id']:02d}, Sample: {sample['sample_id']:04d}\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Draw ALL bounding boxes with different colors\n",
    "    colors = ['r', 'g', 'b', 'y', 'c', 'm', 'orange', 'purple']\n",
    "    if sample['num_objects'] > 0:\n",
    "        for i, obj in enumerate(sample['objects']):\n",
    "            bbox = obj['bbox'].numpy()\n",
    "            x, y, w, h = bbox\n",
    "            color = colors[i % len(colors)]\n",
    "            rect = Rectangle((x, y), w, h, linewidth=2, edgecolor=color, facecolor='none')\n",
    "            axes[0].add_patch(rect)\n",
    "            # Add object ID label\n",
    "            obj_id = obj['obj_id']\n",
    "            axes[0].text(x, y-5, f\"ID:{obj_id}\", color=color, fontsize=10, \n",
    "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # Depth Map\n",
    "    if sample['depth'] is not None:\n",
    "        depth = sample['depth'].numpy()\n",
    "        axes[1].imshow(depth, cmap='viridis')\n",
    "        axes[1].set_title(\"Depth Map\")\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "    # Mask\n",
    "    if sample['mask'] is not None:\n",
    "        mask = sample['mask'].numpy()\n",
    "        axes[2].imshow(mask, cmap='gray')\n",
    "        axes[2].set_title(\"Segmentation Mask\")\n",
    "        axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Stampa informazioni su TUTTI gli oggetti\n",
    "    print(f\"\\nüéØ Found {sample['num_objects']} object(s) in this image:\")\n",
    "    for i, obj in enumerate(sample['objects']):\n",
    "        print(f\"\\n  Object #{i+1} (ID: {obj['obj_id']}):\")\n",
    "        print(f\"    Rotation matrix:\\n{obj['rotation'].numpy()}\")\n",
    "        print(f\"    Translation vector: {obj['translation'].numpy()}\")\n",
    "        print(f\"    Bounding Box [x, y, w, h]: {obj['bbox'].numpy()}\")\n",
    "    \n",
    "    if sample['cam_K'] is not None:\n",
    "        print(\"\\nüì∑ Camera Intrinsics:\")\n",
    "        print(f\"{sample['cam_K'].numpy()}\")\n",
    "\n",
    "# Visualizza 3 campioni casuali\n",
    "indices = random.sample(range(len(train_dataset)), min(3, len(train_dataset)))\n",
    "\n",
    "for idx in indices:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Sample #{idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    sample = train_dataset[idx]\n",
    "    visualize_sample(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c342844",
   "metadata": {},
   "source": [
    "## 6. Crea DataLoaders per il training\n",
    "\n",
    "Questo codice crea oggetti DataLoader che wrappano i dataset:\n",
    "\n",
    "- Internamente chiama probabilmente CustomDataset (come il primo blocco)\n",
    "\n",
    "- Poi li wrappa in torch.utils.data.DataLoader\n",
    "\n",
    "- Fornisce funzionalit√† aggiuntive:\n",
    "\n",
    "- Batching automatico (batch_size=4)\n",
    "\n",
    "- Shuffling del training set\n",
    "\n",
    "- Parallelizzazione con num_workers\n",
    "\n",
    "- Iterazione efficiente per il training\n",
    "\n",
    "Usa quando:\n",
    "\n",
    "- Stai facendo training/testing con PyTorch\n",
    "\n",
    "- Hai bisogno di batching automatico\n",
    "\n",
    "- Vuoi codice pi√π conciso e standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea train e test loaders\n",
    "train_loader, test_loader = create_dataloaders(\n",
    "    dataset_root=dataset_root,\n",
    "    batch_size=4,\n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    train_ratio=Config.TRAIN_TEST_RATIO,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Test di un batch\n",
    "print(\"\\nüîç Testing a batch from train_loader...\")\n",
    "for batch in train_loader:\n",
    "    print(f\"   RGB batch shape: {batch['rgb'].shape}\")\n",
    "    if batch['depth'] is not None:\n",
    "        print(f\"   Depth batch shape: {batch['depth'].shape}\")\n",
    "    if batch['mask'] is not None:\n",
    "        print(f\"   Mask batch shape: {batch['mask'].shape}\")\n",
    "    print(f\"   Batch contains {len(batch['folder_id'])} samples\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47f011",
   "metadata": {},
   "source": [
    "## 7. Esplora il contenuto di gt.yml e info.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dfc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trova il primo gt.yml disponibile\n",
    "gt_file = next(Config.LINEMOD_ROOT.rglob('gt.yml'), None)\n",
    "info_file = next(Config.LINEMOD_ROOT.rglob('info.yml'), None)\n",
    "\n",
    "if gt_file:\n",
    "    print(\"üìÑ Ground Truth (gt.yml) content:\")\n",
    "    with open(gt_file, 'r') as f:\n",
    "        gt_data = yaml.safe_load(f)\n",
    "        # Il file YAML ha struttura: {sample_id: [list of objects]}\n",
    "        if isinstance(gt_data, dict):\n",
    "            first_key = list(gt_data.keys())[0]\n",
    "            print(f\"Sample ID: {first_key}\")\n",
    "            if isinstance(gt_data[first_key], list):\n",
    "                print(yaml.dump(gt_data[first_key][0], default_flow_style=False))\n",
    "            else:\n",
    "                print(yaml.dump(gt_data[first_key], default_flow_style=False))\n",
    "        else:\n",
    "            print(yaml.dump(gt_data[0], default_flow_style=False))\n",
    "\n",
    "if info_file:\n",
    "    print(\"\\nüìÑ Info (info.yml) content:\")\n",
    "    with open(info_file, 'r') as f:\n",
    "        info_data = yaml.safe_load(f)\n",
    "        # Il file YAML ha struttura: {sample_id: [list of objects]}\n",
    "        if isinstance(info_data, dict):\n",
    "            first_key = list(info_data.keys())[0]\n",
    "            print(f\"Sample ID: {first_key}\")\n",
    "            # Controlla se la chiave esiste e che tipo di dato √®\n",
    "            if first_key in info_data:\n",
    "                if isinstance(info_data[first_key], list) and len(info_data[first_key]) > 0:\n",
    "                    print(yaml.dump(info_data[first_key][0], default_flow_style=False))\n",
    "                else:\n",
    "                    print(yaml.dump(info_data[first_key], default_flow_style=False))\n",
    "            else:\n",
    "                print(\"Struttura non standard, mostra tutto:\")\n",
    "                print(yaml.dump(info_data, default_flow_style=False))\n",
    "        else:\n",
    "            print(yaml.dump(info_data[0] if isinstance(info_data, list) else info_data, default_flow_style=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polito-aml-6d-pose-estimation-LevBIKLF-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
