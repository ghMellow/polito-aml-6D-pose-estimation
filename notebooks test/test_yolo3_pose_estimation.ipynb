{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82477640",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7a8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project root: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation\n",
      "üñ•Ô∏è  Device: mps\n",
      "   ‚úÖ Apple Silicon GPU detected (MPS)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from config import Config\n",
    "from models.pose_estimator import PoseEstimator\n",
    "from dataset.custom_dataset import PoseDataset\n",
    "from utils.transforms import (\n",
    "    quaternion_to_rotation_matrix,\n",
    "    crop_image_from_bbox,\n",
    "    get_pose_transforms,\n",
    "    project_3d_points\n",
    ")\n",
    "from utils.metrics import (\n",
    "    load_all_models,\n",
    "    load_models_info,\n",
    "    compute_add\n",
    ")\n",
    "\n",
    "print(f\"üìÇ Project root: {project_root}\")\n",
    "print(f\"üñ•Ô∏è  Device: {Config.DEVICE}\")\n",
    "\n",
    "# Show device info\n",
    "if Config.DEVICE == 'mps':\n",
    "    print(f\"   ‚úÖ Apple Silicon GPU detected (MPS)\")\n",
    "elif Config.DEVICE == 'cuda':\n",
    "    print(f\"   ‚úÖ NVIDIA GPU detected (CUDA)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Using CPU (slower training)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a31086",
   "metadata": {},
   "source": [
    "## 2. Train and then Load Model & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1684369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Using device: mps\n",
      "\n",
      "üì¶ Loading dataset from: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/test/../data/Linemod_preprocessed\n",
      "‚úÖ PoseDataset initialized: 3759 train samples\n",
      "‚úÖ PoseDataset initialized: 3759 train samples\n",
      "‚úÖ PoseDataset initialized: 21218 test samples\n",
      "\n",
      "üìä Pose DataLoaders created:\n",
      "   Training samples: 3759\n",
      "   Training batches: 470\n",
      "   Test samples: 21218\n",
      "   Test batches: 2653\n",
      "\n",
      "üìê Loading 3D models for ADD metric...\n",
      "‚úÖ Loaded model 01: 5841 points\n",
      "‚úÖ Loaded model 02: 38325 points\n",
      "‚úÖ Loaded model 03: 40759 points\n",
      "‚úÖ PoseDataset initialized: 21218 test samples\n",
      "\n",
      "üìä Pose DataLoaders created:\n",
      "   Training samples: 3759\n",
      "   Training batches: 470\n",
      "   Test samples: 21218\n",
      "   Test batches: 2653\n",
      "\n",
      "üìê Loading 3D models for ADD metric...\n",
      "‚úÖ Loaded model 01: 5841 points\n",
      "‚úÖ Loaded model 02: 38325 points\n",
      "‚úÖ Loaded model 03: 40759 points\n",
      "‚úÖ Loaded model 04: 18995 points\n",
      "‚úÖ Loaded model 04: 18995 points\n",
      "‚úÖ Loaded model 05: 22831 points\n",
      "‚úÖ Loaded model 06: 15736 points\n",
      "‚úÖ Loaded model 07: 16573 points\n",
      "‚úÖ Loaded model 08: 12655 points\n",
      "‚úÖ Loaded model 09: 7912 points\n",
      "‚úÖ Loaded model 05: 22831 points\n",
      "‚úÖ Loaded model 06: 15736 points\n",
      "‚úÖ Loaded model 07: 16573 points\n",
      "‚úÖ Loaded model 08: 12655 points\n",
      "‚úÖ Loaded model 09: 7912 points\n",
      "‚úÖ Loaded model 10: 18473 points\n",
      "‚úÖ Loaded model 11: 7479 points\n",
      "‚úÖ Loaded model 12: 15972 points\n",
      "‚úÖ Loaded model 13: 18216 points\n",
      "‚úÖ Loaded model 14: 27435 points\n",
      "‚úÖ Loaded model 10: 18473 points\n",
      "‚úÖ Loaded model 11: 7479 points\n",
      "‚úÖ Loaded model 12: 15972 points\n",
      "‚úÖ Loaded model 13: 18216 points\n",
      "‚úÖ Loaded model 14: 27435 points\n",
      "‚úÖ Loaded model 15: 16559 points\n",
      "\n",
      "üèóÔ∏è  Creating model...\n",
      "/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "‚úÖ Loaded model 15: 16559 points\n",
      "\n",
      "üèóÔ∏è  Creating model...\n",
      "/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "‚úÖ PoseEstimator initialized\n",
      "   Backbone: ResNet-50 (pretrained=True, frozen=True)\n",
      "   Feature dim: 2048\n",
      "   Output: 7 values (4 quaternion + 3 translation)\n",
      "   Dropout: 0.3\n",
      "‚úÖ PoseEstimator initialized\n",
      "   Backbone: ResNet-50 (pretrained=True, frozen=True)\n",
      "   Feature dim: 2048\n",
      "   Output: 7 values (4 quaternion + 3 translation)\n",
      "   Dropout: 0.3\n",
      "\n",
      "üìä Model Parameters:\n",
      "   Total: 26,137,671\n",
      "   Trainable: 2,629,639 (10.1%)\n",
      "   ‚ö° Backbone frozen - training only head (~3-4x faster!)\n",
      "‚úÖ PoseLoss initialized\n",
      "   Œª_trans: 1.0\n",
      "   Œª_rot: 10.0\n",
      "‚ö†Ô∏è  Mixed precision (AMP) not supported on MPS, using FP32\n",
      "\n",
      "üöÄ Starting training for 2 epochs...\n",
      "   Effective batch size: 16\n",
      "   Mixed precision: False\n",
      "Epoch 1:   0%|                                          | 0/470 [00:00<?, ?it/s]\n",
      "üìä Model Parameters:\n",
      "   Total: 26,137,671\n",
      "   Trainable: 2,629,639 (10.1%)\n",
      "   ‚ö° Backbone frozen - training only head (~3-4x faster!)\n",
      "‚úÖ PoseLoss initialized\n",
      "   Œª_trans: 1.0\n",
      "   Œª_rot: 10.0\n",
      "‚ö†Ô∏è  Mixed precision (AMP) not supported on MPS, using FP32\n",
      "\n",
      "üöÄ Starting training for 2 epochs...\n",
      "   Effective batch size: 16\n",
      "   Mixed precision: False\n",
      "Epoch 1:   6%| | 30/470 [03:40<41:00,  5.59s/it, loss=353.7132, trans=345.3997, ^Cary/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/tqdm/std.py\"\u001b[0m, line \u001b[35m1181\u001b[0m, in \u001b[35m__iter__\u001b[0m\n",
      "    for obj in \u001b[1;31miterable\u001b[0m:\n",
      "               \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/test/../scripts/train_pose.py\", line 432, in <module>\n",
      "    main()\n",
      "  File \"/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/test/../scripts/train_pose.py\", line 357, in main\n",
      "    train_metrics = train_epoch(\n",
      "  File \"/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/test/../scripts/train_pose.py\", line 119, in train_epoch\n",
      "    for batch_idx, batch in enumerate(pbar):\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1482, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1444, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1275, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 111, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 1148, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py\", line 398, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in atexit callback <function _exit_function at 0x107d37100>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/util.py\", line 349, in _exit_function\n",
      "    p.join()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 6401) is killed by signal: Interrupt: 2. \n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "^Cary/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/tqdm/std.py\"\u001b[0m, line \u001b[35m1181\u001b[0m, in \u001b[35m__iter__\u001b[0m\n",
      "    for obj in \u001b[1;31miterable\u001b[0m:\n",
      "               \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/test/../scripts/train_pose.py\", line 432, in <module>\n",
      "    main()\n",
      "  File \"/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/test/../scripts/train_pose.py\", line 357, in main\n",
      "    train_metrics = train_epoch(\n",
      "  File \"/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/test/../scripts/train_pose.py\", line 119, in train_epoch\n",
      "    for batch_idx, batch in enumerate(pbar):\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1482, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1444, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1275, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 111, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 1148, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py\", line 398, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in atexit callback <function _exit_function at 0x107d37100>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/util.py\", line 349, in _exit_function\n",
      "    p.join()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/polito-aml-6d-pose-estimation-LevBIKLF-py3.13/lib/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 6401) is killed by signal: Interrupt: 2. \n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "\n",
      "============================================================\n",
      "üí° Training Info:\n",
      "============================================================\n",
      "   Device: mps\n",
      "   Checkpoint: checkpoints/best_model.pth\n",
      "\n",
      "üìä Options comparison:\n",
      "   1. Freeze backbone: 2-3 min, ~3M params, good for testing\n",
      "   2. Train all (few epochs): 10-15 min, ~26M params, better quality\n",
      "   3. Full training: 2-4 hours, best results\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "üí° Training Info:\n",
      "============================================================\n",
      "   Device: mps\n",
      "   Checkpoint: checkpoints/best_model.pth\n",
      "\n",
      "üìä Options comparison:\n",
      "   1. Freeze backbone: 2-3 min, ~3M params, good for testing\n",
      "   2. Train all (few epochs): 10-15 min, ~26M params, better quality\n",
      "   3. Full training: 2-4 hours, best results\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Training Options - Choose your speed/quality tradeoff!\n",
    "\n",
    "# Option 1: SUPER FAST TEST (2-3 min) - Freeze backbone, train only head\n",
    "# ‚ö° Trains only ~3M params instead of ~26M - Perfect for quick testing!\n",
    "!python ../scripts/train_pose.py \\\n",
    "    --epochs 2 \\\n",
    "    --batch_size 8 \\\n",
    "    --gradient_accum_steps 2 \\\n",
    "    --val_interval 1 \\\n",
    "    --save_interval 1 \\\n",
    "    --num_workers 2 \\\n",
    "    --freeze_backbone\n",
    "\n",
    "# Option 2: MEDIUM TRAINING (10-15 min) - Train everything, few epochs\n",
    "# !python ../scripts/train_pose.py \\\n",
    "#     --epochs 5 \\\n",
    "#     --batch_size 4 \\\n",
    "#     --gradient_accum_steps 2 \\\n",
    "#     --val_interval 1 \\\n",
    "#     --save_interval 5 \\\n",
    "#     --num_workers 2\n",
    "\n",
    "# Option 3: FULL TRAINING (2-4 hours) - Best results\n",
    "# !python ../scripts/train_pose.py \\\n",
    "#     --epochs 50 \\\n",
    "#     --batch_size 8 \\\n",
    "#     --gradient_accum_steps 4 \\\n",
    "#     --val_interval 5 \\\n",
    "#     --save_interval 10 \\\n",
    "#     --use_wandb\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° Training Info:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Device: {Config.DEVICE}\")\n",
    "print(f\"   Checkpoint: checkpoints/best_model.pth\")\n",
    "print(\"\\nüìä Options comparison:\")\n",
    "print(\"   1. Freeze backbone: 2-3 min, ~3M params, good for testing\")\n",
    "print(\"   2. Train all (few epochs): 10-15 min, ~26M params, better quality\")\n",
    "print(\"   3. Full training: 2-4 hours, best results\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7cdca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Checkpoint not found: /Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml-6D_pose_estimation/checkpoints/best_model.pth\n",
      "   Please train the model first using scripts/train_pose.py\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "checkpoint_path = Config.CHECKPOINT_DIR / 'best_model.pth'\n",
    "\n",
    "if not checkpoint_path.exists():\n",
    "    print(f\"‚ùå Checkpoint not found: {checkpoint_path}\")\n",
    "    print(\"   Please train the model first using scripts/train_pose.py\")\n",
    "else:\n",
    "    print(f\"üì¶ Loading checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Create model\n",
    "    device = torch.device(Config.DEVICE)\n",
    "    model = PoseEstimator(pretrained=False, dropout=Config.POSE_DROPOUT)\n",
    "    \n",
    "    # Load weights\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Print checkpoint info\n",
    "    epoch = checkpoint.get('epoch', 'N/A')\n",
    "    metrics = checkpoint.get('metrics', {})\n",
    "    print(f\"‚úÖ Model loaded successfully\")\n",
    "    print(f\"   Epoch: {epoch}\")\n",
    "    if 'mean_add' in metrics:\n",
    "        print(f\"   Val ADD: {metrics['mean_add']:.2f} mm\")\n",
    "    if 'accuracy' in metrics:\n",
    "        print(f\"   Val Accuracy: {metrics['accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "print(f\"\\nüì¶ Loading test dataset...\")\n",
    "test_dataset = PoseDataset(\n",
    "    dataset_root=str(Config.DATA_ROOT),\n",
    "    split='test',\n",
    "    crop_margin=Config.POSE_CROP_MARGIN,\n",
    "    output_size=Config.POSE_IMAGE_SIZE\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Load 3D models for visualization\n",
    "print(f\"\\nüìê Loading 3D models...\")\n",
    "models_dict = load_all_models(Config.MODELS_PATH)\n",
    "models_info = load_models_info(Config.MODELS_INFO_PATH)\n",
    "print(f\"‚úÖ Loaded {len(models_dict)} 3D models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284efcdc",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_bbox_corners(model_points):\n",
    "    \"\"\"Get 8 corners of 3D bounding box from model points.\"\"\"\n",
    "    min_xyz = model_points.min(axis=0)\n",
    "    max_xyz = model_points.max(axis=0)\n",
    "    \n",
    "    corners = np.array([\n",
    "        [min_xyz[0], min_xyz[1], min_xyz[2]],\n",
    "        [max_xyz[0], min_xyz[1], min_xyz[2]],\n",
    "        [max_xyz[0], max_xyz[1], min_xyz[2]],\n",
    "        [min_xyz[0], max_xyz[1], min_xyz[2]],\n",
    "        [min_xyz[0], min_xyz[1], max_xyz[2]],\n",
    "        [max_xyz[0], min_xyz[1], max_xyz[2]],\n",
    "        [max_xyz[0], max_xyz[1], max_xyz[2]],\n",
    "        [min_xyz[0], max_xyz[1], max_xyz[2]]\n",
    "    ])\n",
    "    \n",
    "    return corners\n",
    "\n",
    "\n",
    "def draw_3d_bbox(ax, corners_2d, color='g', linewidth=2, label=None):\n",
    "    \"\"\"Draw 3D bounding box on image.\"\"\"\n",
    "    # Define edges of bounding box\n",
    "    edges = [\n",
    "        [0, 1], [1, 2], [2, 3], [3, 0],  # Bottom face\n",
    "        [4, 5], [5, 6], [6, 7], [7, 4],  # Top face\n",
    "        [0, 4], [1, 5], [2, 6], [3, 7]   # Vertical edges\n",
    "    ]\n",
    "    \n",
    "    # Draw edges\n",
    "    for i, (start, end) in enumerate(edges):\n",
    "        if i == 0 and label:\n",
    "            ax.plot([corners_2d[start, 0], corners_2d[end, 0]],\n",
    "                   [corners_2d[start, 1], corners_2d[end, 1]],\n",
    "                   color=color, linewidth=linewidth, label=label)\n",
    "        else:\n",
    "            ax.plot([corners_2d[start, 0], corners_2d[end, 0]],\n",
    "                   [corners_2d[start, 1], corners_2d[end, 1]],\n",
    "                   color=color, linewidth=linewidth)\n",
    "\n",
    "\n",
    "def visualize_pose_prediction(rgb_crop, rgb_full, K, pred_R, pred_t, gt_R, gt_t, \n",
    "                              model_points, obj_name, add_error):\n",
    "    \"\"\"Visualize pose prediction with 3D bounding box overlay.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot 1: Cropped RGB input\n",
    "    axes[0].imshow(rgb_crop)\n",
    "    axes[0].set_title(f\"Input Crop\\n{obj_name}\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Get 3D bbox corners\n",
    "    corners_3d = get_3d_bbox_corners(model_points)\n",
    "    \n",
    "    # Plot 2: Predicted pose\n",
    "    axes[1].imshow(rgb_full)\n",
    "    pred_corners_2d = project_3d_points(corners_3d, pred_R, pred_t, K)\n",
    "    draw_3d_bbox(axes[1], pred_corners_2d, color='lime', linewidth=2, label='Predicted')\n",
    "    axes[1].set_title(f\"Predicted Pose\\nADD: {add_error:.2f} mm\")\n",
    "    axes[1].axis('off')\n",
    "    axes[1].legend(loc='upper right')\n",
    "    \n",
    "    # Plot 3: Ground truth pose\n",
    "    axes[2].imshow(rgb_full)\n",
    "    gt_corners_2d = project_3d_points(corners_3d, gt_R, gt_t, K)\n",
    "    draw_3d_bbox(axes[2], gt_corners_2d, color='cyan', linewidth=2, label='Ground Truth')\n",
    "    axes[2].set_title(\"Ground Truth Pose\")\n",
    "    axes[2].axis('off')\n",
    "    axes[2].legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0bb06",
   "metadata": {},
   "source": [
    "## 4. Test on Individual Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e317861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random test samples\n",
    "import random\n",
    "\n",
    "num_samples = 5\n",
    "sample_indices = random.sample(range(len(test_dataset)), num_samples)\n",
    "\n",
    "print(f\"Testing on {num_samples} random samples...\\n\")\n",
    "\n",
    "for idx in sample_indices:\n",
    "    # Get sample\n",
    "    sample = test_dataset[idx]\n",
    "    \n",
    "    # Prepare input\n",
    "    rgb_crop_tensor = sample['rgb_crop'].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        pred_quat, pred_trans = model(rgb_crop_tensor)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    pred_quat = pred_quat.squeeze(0).cpu().numpy()\n",
    "    pred_trans = pred_trans.squeeze(0).cpu().numpy()\n",
    "    gt_quat = sample['quaternion'].numpy()\n",
    "    gt_trans = sample['translation'].numpy()\n",
    "    \n",
    "    # Convert quaternion to rotation matrix\n",
    "    pred_R = quaternion_to_rotation_matrix(torch.tensor(pred_quat)).numpy()\n",
    "    gt_R = quaternion_to_rotation_matrix(torch.tensor(gt_quat)).numpy()\n",
    "    \n",
    "    # Get 3D model\n",
    "    obj_id = sample['obj_id']\n",
    "    model_points = models_dict[obj_id]\n",
    "    obj_name = Config.OBJ_ID_TO_NAME.get(obj_id, f\"Object {obj_id}\")\n",
    "    \n",
    "    # Compute ADD error\n",
    "    is_symmetric = obj_id in Config.SYMMETRIC_OBJECTS\n",
    "    add_error = compute_add(\n",
    "        pred_R, pred_trans,\n",
    "        gt_R, gt_trans,\n",
    "        model_points,\n",
    "        symmetric=is_symmetric\n",
    "    )\n",
    "    \n",
    "    # Get full RGB and camera intrinsics\n",
    "    rgb_full = sample['rgb_full']\n",
    "    K = sample['camera_K'].numpy()\n",
    "    \n",
    "    # Denormalize crop for visualization\n",
    "    rgb_crop_vis = rgb_crop_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "    rgb_crop_vis = (rgb_crop_vis * np.array([0.229, 0.224, 0.225]) + \n",
    "                   np.array([0.485, 0.456, 0.406]))\n",
    "    rgb_crop_vis = (rgb_crop_vis * 255).clip(0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Visualize\n",
    "    print(f\"Sample {idx}: {obj_name}\")\n",
    "    print(f\"  ADD Error: {add_error:.2f} mm\")\n",
    "    print(f\"  Symmetric: {is_symmetric}\\n\")\n",
    "    \n",
    "    visualize_pose_prediction(\n",
    "        rgb_crop_vis, rgb_full, K,\n",
    "        pred_R, pred_trans,\n",
    "        gt_R, gt_trans,\n",
    "        model_points, obj_name, add_error\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2dab3",
   "metadata": {},
   "source": [
    "## 5. Evaluate on Full Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluating on {len(test_dataset)} test samples...\\n\")\n",
    "\n",
    "# Storage for results\n",
    "add_errors_per_object = {obj_id: [] for obj_id in Config.OBJ_ID_TO_NAME.keys()}\n",
    "all_add_errors = []\n",
    "\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    for idx in tqdm(range(len(test_dataset))):\n",
    "        sample = test_dataset[idx]\n",
    "        \n",
    "        # Predict\n",
    "        rgb_crop = sample['rgb_crop'].unsqueeze(0).to(device)\n",
    "        pred_quat, pred_trans = model(rgb_crop)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        pred_quat = pred_quat.squeeze(0).cpu().numpy()\n",
    "        pred_trans = pred_trans.squeeze(0).cpu().numpy()\n",
    "        gt_quat = sample['quaternion'].numpy()\n",
    "        gt_trans = sample['translation'].numpy()\n",
    "        \n",
    "        # Convert to rotation matrix\n",
    "        pred_R = quaternion_to_rotation_matrix(torch.tensor(pred_quat)).numpy()\n",
    "        gt_R = quaternion_to_rotation_matrix(torch.tensor(gt_quat)).numpy()\n",
    "        \n",
    "        # Compute ADD\n",
    "        obj_id = sample['obj_id']\n",
    "        model_points = models_dict[obj_id]\n",
    "        is_symmetric = obj_id in Config.SYMMETRIC_OBJECTS\n",
    "        \n",
    "        add_error = compute_add(\n",
    "            pred_R, pred_trans,\n",
    "            gt_R, gt_trans,\n",
    "            model_points,\n",
    "            symmetric=is_symmetric\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        add_errors_per_object[obj_id].append(add_error)\n",
    "        all_add_errors.append(add_error)\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0268934",
   "metadata": {},
   "source": [
    "## 6. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "mean_add = np.mean(all_add_errors)\n",
    "median_add = np.median(all_add_errors)\n",
    "std_add = np.std(all_add_errors)\n",
    "\n",
    "# Accuracy at threshold\n",
    "threshold_mm = Config.ADD_THRESHOLD * 100  # Convert to mm (assuming diameter ~100mm)\n",
    "accuracy = np.mean([e < threshold_mm for e in all_add_errors]) * 100\n",
    "\n",
    "print(f\"üìä Overall Results:\")\n",
    "print(f\"   Mean ADD: {mean_add:.2f} mm\")\n",
    "print(f\"   Median ADD: {median_add:.2f} mm\")\n",
    "print(f\"   Std ADD: {std_add:.2f} mm\")\n",
    "print(f\"   Accuracy @ {threshold_mm:.1f}mm: {accuracy:.2f}%\")\n",
    "\n",
    "# Per-object statistics\n",
    "print(f\"\\nüì¶ Per-Object Results:\")\n",
    "obj_results = []\n",
    "\n",
    "for obj_id, errors in add_errors_per_object.items():\n",
    "    if len(errors) > 0:\n",
    "        obj_name = Config.OBJ_ID_TO_NAME[obj_id]\n",
    "        mean_err = np.mean(errors)\n",
    "        median_err = np.median(errors)\n",
    "        \n",
    "        # Get object diameter for threshold\n",
    "        diameter = models_info[obj_id]['diameter']\n",
    "        obj_threshold = Config.ADD_THRESHOLD * diameter\n",
    "        obj_acc = np.mean([e < obj_threshold for e in errors]) * 100\n",
    "        \n",
    "        obj_results.append({\n",
    "            'id': obj_id,\n",
    "            'name': obj_name,\n",
    "            'mean': mean_err,\n",
    "            'median': median_err,\n",
    "            'accuracy': obj_acc,\n",
    "            'count': len(errors)\n",
    "        })\n",
    "        \n",
    "        print(f\"   {obj_name:15s} - Mean: {mean_err:6.2f} mm, Accuracy: {obj_acc:5.2f}% ({len(errors)} samples)\")\n",
    "\n",
    "# Sort by mean ADD\n",
    "obj_results.sort(key=lambda x: x['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ADD distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Overall ADD histogram\n",
    "axes[0, 0].hist(all_add_errors, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(mean_add, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_add:.2f} mm')\n",
    "axes[0, 0].axvline(median_add, color='green', linestyle='--', linewidth=2, label=f'Median: {median_add:.2f} mm')\n",
    "axes[0, 0].set_xlabel('ADD Error (mm)')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Overall ADD Error Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Per-object mean ADD\n",
    "obj_names = [r['name'] for r in obj_results]\n",
    "obj_means = [r['mean'] for r in obj_results]\n",
    "axes[0, 1].barh(obj_names, obj_means, color='coral', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Mean ADD Error (mm)')\n",
    "axes[0, 1].set_title('Mean ADD by Object')\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 3: Per-object accuracy\n",
    "obj_accs = [r['accuracy'] for r in obj_results]\n",
    "axes[1, 0].barh(obj_names, obj_accs, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Accuracy (%)')\n",
    "axes[1, 0].set_title(f'Accuracy by Object (threshold: {Config.ADD_THRESHOLD*100}% diameter)')\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "axes[1, 0].set_xlim([0, 100])\n",
    "\n",
    "# Plot 4: ADD boxplot per object\n",
    "add_data = [add_errors_per_object[r['id']] for r in obj_results]\n",
    "bp = axes[1, 1].boxplot(add_data, labels=obj_names, vert=False, patch_artist=True)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('skyblue')\n",
    "axes[1, 1].set_xlabel('ADD Error (mm)')\n",
    "axes[1, 1].set_title('ADD Distribution by Object')\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb262db9",
   "metadata": {},
   "source": [
    "## 7. Best and Worst Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31692fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best and worst predictions\n",
    "sorted_indices = np.argsort(all_add_errors)\n",
    "\n",
    "print(\"üèÜ Best 3 Predictions:\")\n",
    "for i in range(3):\n",
    "    idx = sorted_indices[i]\n",
    "    sample = test_dataset[idx]\n",
    "    obj_name = Config.OBJ_ID_TO_NAME[sample['obj_id']]\n",
    "    print(f\"   {i+1}. {obj_name}: {all_add_errors[idx]:.2f} mm\")\n",
    "\n",
    "print(\"\\n‚ùå Worst 3 Predictions:\")\n",
    "for i in range(3):\n",
    "    idx = sorted_indices[-(i+1)]\n",
    "    sample = test_dataset[idx]\n",
    "    obj_name = Config.OBJ_ID_TO_NAME[sample['obj_id']]\n",
    "    print(f\"   {i+1}. {obj_name}: {all_add_errors[idx]:.2f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7aae3",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This notebook provides comprehensive evaluation of the trained 6D pose estimation model:\n",
    "\n",
    "1. **Individual sample visualization** - Inspect predicted vs GT 3D bounding boxes\n",
    "2. **Full test set evaluation** - Compute ADD metric on all test samples\n",
    "3. **Per-object analysis** - Identify which objects are easiest/hardest to estimate\n",
    "4. **Error distribution** - Understand model performance characteristics\n",
    "\n",
    "**Key Metrics:**\n",
    "- **ADD (Average Distance of Model Points)**: Average distance between transformed model points\n",
    "- **ADD-S**: Symmetric variant using closest point matching for symmetric objects (eggbox, glue)\n",
    "- **Accuracy**: Percentage of predictions with ADD < 10% of object diameter\n",
    "\n",
    "**Next Steps:**\n",
    "- Fine-tune hyperparameters (learning rate, batch size, loss weights)\n",
    "- Try data augmentation (random crops, color jitter, rotation)\n",
    "- Experiment with different backbones (ResNet-101, EfficientNet)\n",
    "- Add depth information to input (RGB-D)\n",
    "- Implement iterative refinement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polito-aml-6d-pose-estimation-LevBIKLF-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
