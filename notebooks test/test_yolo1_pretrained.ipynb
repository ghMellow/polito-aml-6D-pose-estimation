{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce6bf18",
   "metadata": {},
   "source": [
    "## 1. Import e Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ca012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import glob\n",
    "\n",
    "# Aggiungi il path del progetto\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from models.yolo_detector import YOLODetector, visualize_detections\n",
    "from config import Config\n",
    "\n",
    "print(f\"üìÇ Project root: {project_root}\")\n",
    "print(f\"üéØ Number of classes: {Config.NUM_CLASSES}\")\n",
    "print(f\"üì¶ YOLO model: {Config.YOLO_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc84938",
   "metadata": {},
   "source": [
    "## 2. Inizializza il Modello YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f3dd00",
   "metadata": {},
   "source": [
    "**Nota**: I pesi pre-addestrati YOLO saranno scaricati automaticamente e salvati in `checkpoints/pretrained/` invece che nella directory principale del progetto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il detector (usa automaticamente Config.DEVICE)\n",
    "detector = YOLODetector(\n",
    "    model_name=Config.YOLO_MODEL,\n",
    "    pretrained=True,  # Usa i pesi pre-addestrati su COCO\n",
    "    num_classes=Config.NUM_CLASSES  # LineMOD ha 13 classi\n",
    ")\n",
    "\n",
    "# Mostra info sul modello\n",
    "print(f\"\\nüìä Model Info:\")\n",
    "for key, value in detector.model_info.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149cedb",
   "metadata": {},
   "source": [
    "## 3. Test su Immagine Singola del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7de622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica un'immagine dal dataset\n",
    "dataset_root = Config.DATA_ROOT\n",
    "sample_img_path = dataset_root / 'data' / '01' / 'rgb' / '0000.png'\n",
    "sample_gt_path = dataset_root / 'data' / '01' / 'gt.yml'\n",
    "\n",
    "if sample_img_path.exists():\n",
    "    # Carica immagine\n",
    "    image = np.array(Image.open(sample_img_path).convert('RGB'))\n",
    "    \n",
    "    # Carica ground truth per confronto\n",
    "    gt_data = None\n",
    "    if sample_gt_path.exists():\n",
    "        with open(sample_gt_path, 'r') as f:\n",
    "            gt_data = yaml.safe_load(f)\n",
    "            if 0 in gt_data:  # Image ID 0\n",
    "                print(f\"üìã Ground Truth - {len(gt_data[0])} objects\")\n",
    "                for obj in gt_data[0]:\n",
    "                    print(f\"   Object ID: {obj['obj_id']}, BBox: {obj['obj_bb']}\")\n",
    "    \n",
    "    print(f\"\\nüì∑ Immagine caricata: {sample_img_path}\")\n",
    "    print(f\"   Shape: {image.shape}\")\n",
    "    \n",
    "    # Visualizza immagine originale\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Immagine Originale\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"‚ùå Immagine non trovata: {sample_img_path}\")\n",
    "    print(\"   Assicurati di aver scaricato il dataset con il notebook local_dataset_test.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6e3d0",
   "metadata": {},
   "source": [
    "## 4. Esegui Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_img_path.exists():\n",
    "    # Esegui detection\n",
    "    print(\"\\nüîç Running object detection...\")\n",
    "    detections = detector.detect_objects(\n",
    "        image=image,\n",
    "        conf_threshold=Config.CONF_THRESHOLD\n",
    "    )\n",
    "    \n",
    "    # Mostra risultati\n",
    "    print(f\"\\nüì¶ Detected {len(detections)} objects:\")\n",
    "    for i, det in enumerate(detections):\n",
    "        print(f\"\\n   Object {i+1}:\")\n",
    "        print(f\"      Class: {det['class_name']} (ID: {det['class_id']})\")\n",
    "        print(f\"      Confidence: {det['confidence']:.3f}\")\n",
    "        print(f\"      BBox [x1,y1,x2,y2]: {det['bbox']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9ae8f",
   "metadata": {},
   "source": [
    "## 5. Visualizza Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_img_path.exists() and len(detections) > 0:\n",
    "    # Visualizza detections\n",
    "    vis_image = visualize_detections(image, detections)\n",
    "    \n",
    "    # Mostra risultato\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(vis_image)\n",
    "    plt.title(f\"yolo Detection Results ({len(detections)} objects)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "elif sample_img_path.exists():\n",
    "    print(\"‚ö†Ô∏è  Nessun oggetto rilevato. Prova ad abbassare il conf_threshold.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e518506",
   "metadata": {},
   "source": [
    "## 6. Test su Multiple Immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test su pi√π immagini\n",
    "# import random\n",
    "\n",
    "# # Trova tutte le immagini RGB\n",
    "# rgb_images = list((dataset_root / 'data').rglob('rgb/*.png'))\n",
    "\n",
    "# if len(rgb_images) > 0:\n",
    "#     # Seleziona 4 immagini random\n",
    "#     sample_images = random.sample(rgb_images, min(4, len(rgb_images)))\n",
    "    \n",
    "#     fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "#     axes = axes.flatten()\n",
    "    \n",
    "#     for idx, img_path in enumerate(sample_images):\n",
    "#         # Carica e processa immagine\n",
    "#         img = np.array(Image.open(img_path).convert('RGB'))\n",
    "#         dets = detector.detect_objects(img, conf_threshold=0.3)\n",
    "        \n",
    "#         # Visualizza\n",
    "#         vis_img = visualize_detections(img, dets)\n",
    "#         axes[idx].imshow(vis_img)\n",
    "#         axes[idx].set_title(f\"{img_path.parent.parent.name}/{img_path.name}\\n{len(dets)} objects\")\n",
    "#         axes[idx].axis('off')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     print(\"‚ùå Nessuna immagine trovata nel dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aca0b9",
   "metadata": {},
   "source": [
    "## 7. Prossimi Passi\n",
    "- Attualmente YOLO usa pesi pre-addestrati su COCO (80 classi)\n",
    "- Per LineMOD (13 oggetti specifici) dovrai fare fine-tuning o training da zero\n",
    "- Il modello baseline serve come confronto per la versione estesa con rotazione"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polito-aml-6d-pose-estimation-LevBIKLF-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
